{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:7000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Sep/2024 16:28:09] \"OPTIONS /api/interpret HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recived data:  {'user_select': '오늘의 운세', 'cards': ['Nine of Swords', 'The Hierophant', 'Five of Swords']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\AppData\\Local\\Temp\\ipykernel_12996\\2691127373.py:69: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  general_chain = LLMChain(llm=self.model, prompt=tarot_template_genal)\n",
      "127.0.0.1 - - [06/Sep/2024 16:28:12] \"POST /api/interpret HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  <Response 1143 bytes [200 OK]>\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# 타로카드 라우트\n",
    "@app.route(\"/api/interpret\",methods=[\"POST\"])\n",
    "\n",
    "def tarot_card():\n",
    "    data = request.json\n",
    "    cards = data.get(\"cards\")\n",
    "    reason = data.get(\"reason\")\n",
    "    user_input = data.get(\"user_input\")\n",
    "    user_select = data.get(\"user_select\")\n",
    "    print(\"recived data: \",data)\n",
    "    if not cards or len(cards) != 3:\n",
    "        return jsonify({\"error\": \"카드를 다시 선택해 주세요.\"}),400\n",
    "    \n",
    "    class TarotBot:\n",
    "        def __init__(self, api_key_path):\n",
    "            #OpenAI API 설정\n",
    "            self.api_key = self.load_api_key(api_key_path)\n",
    "            self.model = ChatOpenAI(openai_api_key = self.api_key, model=\"gpt-4o\")\n",
    "\n",
    "        def load_api_key(self, file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                api_key = file.read().strip()\n",
    "                return api_key\n",
    "            \n",
    "        # 사용자 고민이 있을때 타로 해석\n",
    "        def interpret_cards(self, user_input, cards):\n",
    "            try:\n",
    "                tarot_template_reason = PromptTemplate(\n",
    "                    template=(\n",
    "                        \"사용자의 질문: '{user_input}'\\n\"\n",
    "                        \"타로카드: {cards}\\n\"\n",
    "                        \"{cards}의 의미는 한줄로 간략히 출력하고, {user_input}를 주제로 종합한 해석은 최대 500자 이내로 출력해주세요.\"\n",
    "                    ),\n",
    "                    input_variables=[\"user_input\", \"cards\"]\n",
    "                )\n",
    "\n",
    "                reason_chain = LLMChain(llm=self.model, prompt=tarot_template_reason)\n",
    "                reason_response = reason_chain.invoke({\"input\":user_input, \"cards\":cards})\n",
    "                answer = reason_response.strip()\n",
    "        \n",
    "\n",
    "                return jsonify({\"answer\": answer})\n",
    "\n",
    "            except Exception as e:\n",
    "                return \"해석 중 오류가 발생했습니다.\"\n",
    "            \n",
    "        # 일반적인 타로 해석\n",
    "        def general_reading(self, user_select, cards):\n",
    "            cards_str = \", \".join(cards)\n",
    "            try:\n",
    "                tarot_template_genal = PromptTemplate(\n",
    "                    template=(\n",
    "                        \"사용자 선택 카테고리: '{user_select}'\\n\"\n",
    "                        \"타로카드: {cards}\\n\"\n",
    "                        \"{cards}의 의미는 한줄로 간략히 출력하고, {user_select}를 주제로 종합한 해석은 최대 500자 이내로 출력해주세요.\\n\"\n",
    "                    ),\n",
    "                    input_variables=[\"user_select\", \"cards\"]\n",
    "                )\n",
    "\n",
    "                general_chain = LLMChain(llm=self.model, prompt=tarot_template_genal)\n",
    "                general_response = general_chain.invoke({\"user_select\":user_select,\"cards\":cards_str})\n",
    "                \n",
    "                if isinstance(general_response, str):\n",
    "                    answer = general_response.strip()\n",
    "                else:\n",
    "                    answer = general_response\n",
    "                \n",
    "                if len(answer) > 500:\n",
    "                    answer = answer[:500]\n",
    "\n",
    "                return jsonify({\"answer\": answer})\n",
    "\n",
    "            except Exception as e:\n",
    "                print((f\"Error: {e}\"))\n",
    "                return \"일반 해석 중 오류가 발생했습니다.\"\n",
    "            \n",
    "\n",
    "    key_path = \"c:/Users/SMHRD/api.txt\"\n",
    "    try:\n",
    "        tarot = TarotBot(api_key_path=key_path)\n",
    "        if reason:\n",
    "            response = tarot.interpret_cards(user_input,cards)\n",
    "        else:\n",
    "            response = tarot.general_reading(user_select,cards)\n",
    "        print(\"response: \",response)\n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error\",str(e))\n",
    "        return jsonify({\"error\":str(e)}),500\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port=7000) #Flask 서버 포트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
