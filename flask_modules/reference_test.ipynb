{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "MODEL_NAME = \"\"\n",
    "CSV_FILE_PATH = \"C:\\\\Users\\\\SMHRD\\\\Documents\\\\카카오톡 받은 파일\\\\참조자료v3.csv\"\n",
    "\n",
    "class ResponseSearch():\n",
    "    def __init__(self,csv_file_path,model_name):\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.data = self._load_data()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(csv_file_path)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        self.preprocess_embedding()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data = pd.read_csv(self.csv_file_path)\n",
    "        return data\n",
    "\n",
    "    def str_to_vector(embedding_str):\n",
    "        return np.fromstring(embedding_str, sep=\",\")\n",
    "    \n",
    "    def preprocess_embedding(self):\n",
    "        #대처_임베딩의 백터값을 numpy화 : 코사인유사도 비교를 위함.\n",
    "        self.data[\"대처_임베딩\"] = self.data[\"대처_임베딩_백터\"].apply(str_to_vector)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #텍스트 임베딩    \n",
    "    def embed_text(self,text):\n",
    "        inputs = self.tokenizer(text,return_tensor=\"pt\",truncation=True,padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:,0,:].squeeze()\n",
    "        return embeddings.numpy()\n",
    "\n",
    "    #특정 고민유형의 임베딩 데이터 불러오기\n",
    "    def get_cate_embed(self,reason):\n",
    "        cate_data = self.data[self.data[\"유형설명\"]== reason]\n",
    "        #고민 유형별로 수많은 row를 numpy형식으로 한줄로 변경\n",
    "        cate_embeddings = np.array([np.fromstring(emb,sep=',') for emb in cate_data[\"원인_임베딩값\"]])\n",
    "        return cate_embeddings,cate_data\n",
    "    \n",
    "    #가장 적합한 답변 찾는 방법\n",
    "    def find_best_ans(self,user_input,reason):\n",
    "        # 사용자 질문 embedding\n",
    "        user_emd = self.embed_text(user_input)\n",
    "\n",
    "        #특정 고민유형의 임베딩데이터 로드\n",
    "        cate_embedding, cate_data = self.get_cate_embed(reason)\n",
    "\n",
    "        # 유사도 계산\n",
    "        similar = cosine_similarity(user_emd.reshape(1,-1),cate_embedding)\n",
    "        \n",
    "        # 가장 유사도 높은 임베딩의 인덱스찾기\n",
    "        most_sim_idx = np.argmax(similar)\n",
    "\n",
    "        # 가장 유사도 높은 답변데이터\n",
    "        most_sim_entry = cate_data.iloc[most_sim_idx][\"답변\"]\n",
    "        \n",
    "        return most_sim_entry\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
