{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import csv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "\n",
    "class ChatBotTs:\n",
    "    def __init__(self, api_key, csv_file):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.model = ChatOpenAI(temperature=0.7, model_name=\"gpt-4\", openai_api_key=api_key)\n",
    "        self.responses = self.load_response_csv(csv_file)\n",
    "        self.memory = ConversationBufferMemory()\n",
    "\n",
    "    def load_response_csv(self, csv_file):\n",
    "        \"\"\"CSV 파일에서 고민 유형별 응답을 로드\"\"\"\n",
    "        responses = {}\n",
    "        with open(csv_file, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                reason = row[\"유형설명\"].strip()  # 공백 제거\n",
    "                response = row[\"대처\"].strip()    # 공백 제거\n",
    "                responses[reason] = response\n",
    "        return responses\n",
    "\n",
    "    def is_problem(self, user_input):\n",
    "        \"\"\"고민 여부 판단\"\"\"\n",
    "        template = PromptTemplate(\n",
    "            template=\"사용자의 입력은 : '{user_input}'\\n고민, 걱정, 또는 문제를 표현하고 있는지? '예', '아니오','맞다'등 명확하고 간결하게 표현\",\n",
    "            input_variables=[\"user_input\"]\n",
    "        )\n",
    "        ck_chain = LLMChain(llm=self.model, prompt=template)\n",
    "        response = ck_chain.run(user_input=user_input).strip()\n",
    "        pos_res = [\"예\", \"네\", \"맞다\", \"맞습니다\", \"그렇다\",\n",
    "                   \"그렇습니다\", \"고민이라고 판단된다\", \"고민입니다\", \"예, 고민이다\"]\n",
    "        return response in pos_res\n",
    "\n",
    "    def get_problem_reason(self, user_input):\n",
    "        \"\"\"고민 이유 판단\"\"\"\n",
    "        reason_template = PromptTemplate(\n",
    "            template=(\"입력값은 : '{user_input}'\\n\"\n",
    "                      \"고민이라고 판단한 이유는?\\n\"\n",
    "                      \"(예:'가족','결혼/육아','금전사업','대인관계','따돌림','성생활','성추행','연애','외모','응원','이별/이혼','일반고민','자아/성격','정신건강','중독/집착','직장','취업/진로','투병/신체','학업/고시')\\n\"\n",
    "                      \"위의 예시 중에서 하나만 선택하여 답변하세요.\"),\n",
    "            input_variables=[\"user_input\"]\n",
    "        )\n",
    "        reason_chain = LLMChain(llm=self.model, prompt=reason_template)\n",
    "        reason = reason_chain.run(user_input=user_input).strip()\n",
    "            # 제거할 따옴표\n",
    "        if reason.startswith(\"''\") and reason.endswith(\"''\"):\n",
    "            reason = reason[2:-2]\n",
    "        elif reason.startswith(\"'\") and reason.endswith(\"'\"):\n",
    "            reason = reason[1:-1]\n",
    "\n",
    "        print(f\"Extracted reason: '{reason}'\")\n",
    "        return reason\n",
    "\n",
    "    \n",
    "    def process_input(self, user_nick, user_input):\n",
    "        \"\"\"사용자 입력을 처리하고 응답을 생성\"\"\"\n",
    "        print(f\"Processing input: user_nick={user_nick}, user_input={user_input}\")\n",
    "        try:\n",
    "            # 고민 여부 판단\n",
    "            is_problem_flag = self.is_problem(user_input)\n",
    "            print(f\"Is problem flag: {is_problem_flag}\")\n",
    "\n",
    "            if is_problem_flag:\n",
    "                print(\"고민임\")\n",
    "                reason = self.get_problem_reason(user_input).strip()\n",
    "                print(f\"Problem reason: {reason}\")\n",
    "\n",
    "                #고민 이유에 맞는 답변 찾기\n",
    "                reference_data = self.responses.get(\"reason\")\n",
    "\n",
    "                #RAG방식으로 답변 생성\n",
    "                rag_template = PromptTemplate(\n",
    "                    template=\n",
    "                        \"사용자 입력: '{user_input}'\\n\"\n",
    "                        \"자료 : '{reference_data}'\\n\"\n",
    "                        \"{reference_data}를 참조하여 {user_input}에 맞는 답변을 최대 500자 이내로 출력을 해주세요.\",\n",
    "                        input_variables=[\"user_input\",\"reference_data\"]\n",
    "                )\n",
    "                rag_chain = LLMChain(llm=self.model,prompt=rag_template,memory=self.memory)\n",
    "                rag_response = rag_chain.invoke({\"user_input\":user_input, \"reference_data\":reference_data})\n",
    "                answer = rag_response.strip()\n",
    "\n",
    "                return {\n",
    "                    \"user\" : user_nick,\n",
    "                    \"input\" : user_input,\n",
    "                    \"isProblem\" : True,\n",
    "                    \"reason\" : reason,\n",
    "                    \"answer\" : answer\n",
    "\n",
    "                }\n",
    "\n",
    "                # # 고민 이유에 맞는 답변 찾기\n",
    "                # if reason in self.responses:\n",
    "                #     answer = self.responses[reason]\n",
    "                # else:\n",
    "                #     answer = self.responses.get(\"기타\", \"죄송합니다. 해당 고민에 대한 특정 답변을 찾을 수 없습니다. 하지만 귀하의 고민을 듣고 있으며, 힘든 상황을 이해합니다. 필요하다면 전문가와 상담을 받아보는 것도 좋은 방법일 수 있습니다.\")\n",
    "\n",
    "                # # 답변 길이 제한\n",
    "                # if len(answer) > 500:\n",
    "                #     answer = answer[:500] + \"...\"  # 500자 이내로 자르기\n",
    "\n",
    "            else:\n",
    "                # 이전 대화를 기억하면서 대화를 이어나감.\n",
    "                response = self.memory.load_memory_variables({})\n",
    "                response.update({\n",
    "                    \"role\":\"user\",\"content\":user_input\n",
    "                })\n",
    "                gen_chain = LLMChain(llm=self.model,prompt=PromptTemplate(\n",
    "                    template= \"사용자과 AI어시스턴트간의 대화 입니다. AI는 이전 대화를 기억하며,따뜻한말투로 대화합니다.\\n\\n\"\n",
    "                    \"{history}\\n\\n사용자:{user_input}\\nAI(따뜻한말투):\",\n",
    "                    input_variables=[\"history\",\"user_input\"]\n",
    "                    ),\n",
    "                    memory = self.memory\n",
    "                    )\n",
    "                answer = gen_chain.run(user_input=user_input)\n",
    "\n",
    "                return {\n",
    "                    \"user\" : user_nick,\n",
    "                    \"input\" : user_input,\n",
    "                    \"isProblem\" : False,\n",
    "                    \"answer\" : answer\n",
    "                }\n",
    "\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error processing input:\", e)\n",
    "            return {\"error\": f\"Error processing input: {str(e)}\"}\n",
    "        \n",
    "\n",
    "# API 키를 파일에서 읽어오기\n",
    "def load_api_key(file_path='C:\\\\Users\\\\SMHRD\\\\Desktop\\\\ky_api.txt'):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {file_path} not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading API key: {str(e)}\")\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
